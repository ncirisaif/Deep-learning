{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2E_cZYTrwjmd"
   },
   "source": [
    "<h1> LAB 4 : Réseau de neurones à convolution </h1>\n",
    "\n",
    "<p>Pour un ordinateur, une image est une matrice de valeurs correspondant aux pixels. Une image en couleur possède trois canaux. C'est à dire qu'on a 3 valeurs pour chaque pixels. Ces trois valeurs représentent le niveau de rouge, de vert et de bleu. On peut imaginer 3 matrices constituées de valeurs de pixels superposées, donnant une matrice en 3D. Par exemple, pour une image d'une taille de 200 par 200 pixels, sa matrice correspondante aura une taille de 200 multiplié par 200 multiplié par 3 (nombre de canaux). En revanche, pour une image en noir et blanc, sa matrice correspondante ne sera qu'en 2D car possédant qu'un seul canal. Ici, la valeur d'un pixel indique le niveau de gris, cela suffit pour une image en noir et blanc. Les valeurs d'un pixel sont mappées sur 256 bits, c'est-à-dire allant de 0 à 255.\n",
    "Lorsqu'on compare deux images directement entres elles, s’il y a ne serait-ce qu’un pixel contenant différentes valeurs, alors les images sont considérées comme étant différentes par l’ordinateur. C’est là que les CNNs entrent en jeu.    \n",
    "</p>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ThdzttN-wjmh"
   },
   "source": [
    "<h2> Filte </h2>\n",
    "Comme une image, le filtre est une matrice de valeurs mais elle a généralement de petites dimensions et bien souvent carrées. La taille de filtre la plus utilisée est de 3 par 3.\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2i0chZPCwjmj"
   },
   "source": [
    "Un filtre sert à faire extraire certaines caractéristiques d'une image donnée (couleur, contour, luminosité, netteté, etc...). Ce filtre va etre déplacé par pas successifs sur l'ensemble de image.\n",
    "![image.png](attachment:image.png)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qc4-I5NSwjmk"
   },
   "source": [
    "Pour chaque position du filtre, les valeurs des deux matrices en superposition (filtre et image à traiter) sont multipliées. Chaque valeur ainsi inférée est projetée dans une nouvelle matrice. Cette matrice représente une nouvelle image qui fait ressortir les caractéristiques recherchées au travers du filtre.\n",
    "L'image ci-dessous montre un exemple de calcul. Les valeurs de l'image à traiter sont anormalement petites, mais c'est juste pour comprendre plus facilement le calcul effectué:\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "En fonction des valeurs et de la taille de la matrice du filtre, nous obtenons une nouvelle image plus ou moins modifiée. Par exemple, avec une première image comme celle affichée ci-dessous, on peut la transformer dans le but de produire plusieurs variantes. Voici le résultat de différentes transformations à l'aide de plusieurs filtres couramment utilisés (détection de bord, floutage, etc...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IxM8gvSGwjml"
   },
   "source": [
    "![image.png](attachment:image.png)\n",
    "\n",
    "<p>Le nombre de filtres determinera le nombre de caractéristiques détectées. Ce nombre est appelé la profondeur. L'usage de filtres est la base dans un réseau à convolution. En pratique, lors de la phase d'entrainement, plusieurs filtres sont testés avec des valeurs différentes. Les meilleures, par rapport au jeu d'entrainement, sont retenues. Les paramètres essentiels doivent être précisés avant l'entrainement, notamment: le nombre, la taille des filtres et leur pas de déplacement.</p>\n",
    "\n",
    "</p>Il est préférable de ne pas utiliser de filtres trop petits ou un nombre de filtres trop important car cela peut entraîner un sur-apprentissage.</p>\n",
    "\n",
    " \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CqUDXQLSwjmn"
   },
   "source": [
    "<h2> Le Pooling</h2>\n",
    "Le Pooling est un procédé important dans un réseau à convolution. En extrayant les valeurs importantes des pixels, il permet de réduire une image tout en conservant les caractéristiques pertinentes. La méthode la plus utilisée est le \"Max Pooling\". Elle consiste à réduire l'image en conservant les valeurs les plus grandes des pixels. Pour ce faire, on a une tuile qui se déplace (comme un filtre) sur la surface de notre image. À chaque position de la tuile, on extrait la valeur la plus haute et ne retient que celle là. Cela produit une nouvelle image avec uniquement les valeurs remarquables de l'image.\n",
    "\n",
    "L'image ci dessous montre un exemple de Pooling. La tuile a, ici, des dimensions de 3 par 3. L'image de 9 par 9 pixels de départ est réduite en une image de 7 par 7 pixels.\n",
    "![image.png](attachment:image.png)\n",
    "En réduisant l'image, le nombre de données traitées diminue et donc le temps de calcul sera aussi réduit. \n",
    "Il existe d'autres méthodes que le \"Max Pooling\", par exemple:<ul>\n",
    "\n",
    "<li>\"Average Pooling\" : Moyenne de toutes les valeurs recouvertes par la tuile.</li>\n",
    "\n",
    "<li>\"Pooling stochastique\" : Ne retient qu'une seule valeur, comme le \"Max Pooling\", mais en se basant sur une méthode probabiliste.</li></ul>\n",
    "\n",
    "En pratique, le \"Max Pooling\" est la méthode qui donne le plus souvent les meilleurs resultats.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cStIscDuwjmo"
   },
   "source": [
    "<h2>La convolution</h2>\n",
    "<p>Le principe d'un réseau à convolution, c'est l'enchainement d'étapes. Chaque étape consiste à appliquer des filtres puis une phase de Pooling sur le résulat de chaque filtre.\n",
    "L'image obtenue après la première étape est réutilisée en entrée de l'étape suivante (filtrage + pooling) et ainsi de suite... Chaque étape est appellé un niveau. Un réseau à convolution peut avoir plusieurs niveaux.\n",
    "\n",
    "Lors de l'apprentissage, chaque niveau de convolution doit retenir les filtres les plus pertinents. Cette selection est opérée grâce à un réseau neuronal interne à chaque niveau de convolution. Comme dans un réseau neuronal classique, les poids et biais de ce réseau évoluent; le critère de convergence étant, que les patterns (\"images\") en sortie caractérisent le mieux l'image de départ.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v5IcajP3wjmq"
   },
   "source": [
    "<h1> Travail demandé </h1>\n",
    "\n",
    "<p>Durant cette séance est nous allons classer les images en niveaux de gris de chiffres manuscrits (28 pixels par 28 pixels), dans leurs 10 catégories (0 à 9) en utilisant un réseau de neurones  à convolution . Implémenter un réseau neuronal composé de couches convolutives et entièrement connectées pour classer les chiffres manuscrits de l'ensemble de données MNIST. L'ensemble de données étiqueté se compose de 42000 images de taille 28x28 = 784 pixels (niveau de gris), y compris les étiquettes correspondantes de 0, .., 9. L'ensemble de test comprend 28 000 images. Chaque image est normalisée de telle sorte que chaque pixel prend des valeurs dans la plage [0,1].\n",
    "\n",
    "</p> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 79
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2977,
     "status": "ok",
     "timestamp": 1582724991793,
     "user": {
      "displayName": "Salma ACHOUR",
      "photoUrl": "",
      "userId": "03683727301665282596"
     },
     "user_tz": -60
    },
    "id": "JKpJK9zjwjmr",
    "outputId": "e9d8340e-919d-496c-eb05-bb40797fc262"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5N8ofRf9wjmx"
   },
   "outputs": [],
   "source": [
    "# Initialisation\n",
    "batch_size = 10\n",
    "num_classes = 10\n",
    "epochs = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LHydSMwbwjm1"
   },
   "outputs": [],
   "source": [
    "# input image dimensions\n",
    "img_rows, img_cols = 28,28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3292,
     "status": "ok",
     "timestamp": 1582724992126,
     "user": {
      "displayName": "Salma ACHOUR",
      "photoUrl": "",
      "userId": "03683727301665282596"
     },
     "user_tz": -60
    },
    "id": "_JyfutE2wjm5",
    "outputId": "4b1c7805-f4f0-464c-a554-c3981ec53e02"
   },
   "outputs": [],
   "source": [
    "# load the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ImJoYMTdwjm8"
   },
   "outputs": [],
   "source": [
    "# reshape images \n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (60000, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0IfRJATPwjnA"
   },
   "outputs": [],
   "source": [
    "# Normalise images\n",
    "x_train =x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255.0\n",
    "x_test /= 255.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YzhQQGDmwjnC"
   },
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "train_labels = to_categorical(y_train)\n",
    "test_labels = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IPkyXk3RwjnF"
   },
   "outputs": [],
   "source": [
    "#define the model  \n",
    "model = Sequential()\n",
    "#keras.layers.Conv2D(filters, kernel_size, strides=(1, 1), padding='valid')\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1))) #Conv2D avec 32 filters , kernel size 3*3 , relu activation , input shape     \n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu')) #Conv2D avec 64 filters , kernel size 3*3 , relu activation\n",
    "model.add(layers.MaxPooling2D((2, 2))) #MaxPooling2D avec pool_size 2*2\n",
    "model.add(layers.Flatten()) # Flatten\n",
    "model.add(layers.Dense(128, activation='relu')) # Dense avec 128 units \n",
    "model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hXkw6raHwjnH"
   },
   "outputs": [],
   "source": [
    "#Compile the model \n",
    "model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sP_ilApZwjnJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 318s 5ms/sample - loss: 0.0408 - accuracy: 0.9872\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 330s 6ms/sample - loss: 0.0257 - accuracy: 0.9924\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 350s 6ms/sample - loss: 0.0171 - accuracy: 0.9947\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 349s 6ms/sample - loss: 0.0120 - accuracy: 0.9963\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 342s 6ms/sample - loss: 0.0093 - accuracy: 0.9973\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x65761cac8>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the model \n",
    "model.fit(x_train, train_labels, epochs=5, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1FQcuIE1wjnM"
   },
   "outputs": [],
   "source": [
    "score = model.evaluate()\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Notebook4_CNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
